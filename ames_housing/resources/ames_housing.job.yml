# The job that triggers ames_housing_pipeline.
resources:
  jobs:
    ames_housing_job:
      name: ames_housing_job

      trigger:
        # Run this job every day, exactly one day from the last run; see https://docs.databricks.com/api/workspace/jobs/create#trigger
        periodic:
          interval: 1
          unit: DAYS

      email_notifications:
        on_failure: ${var.notifications}

      environments:
        - environment_key: primary
          spec:
            environment_version: ${var.serverless_environment_version}
            dependencies: []

        - environment_key: make_ames
          spec:
            environment_version: ${var.serverless_environment_version}
            dependencies: ["kagglehub"]

      parameters:
        - name: catalog_use
          default: ${var.catalog}
        - name: schema_use 
          default: ${resources.schemas.ames_housing_schema.name}
        - name: volume_path_use
          default: ${resources.volumes.ames_housing_landing_volume.volume_path}
        - name: ml_model_name_use
          default: ${resources.registered_models.ames_housing_model.name}
        - name: ml_model_storage_location
          default: ${resources.volumes.model_storage_location_volume.volume_path}
        - name: ml_model_experiments_name_use
          default: ${resources.experiments.ames_housing_experiment.name}
          

      tasks:
        - task_key: copy_data_set
          notebook_task: 
            notebook_path: ../src/00-copy-csv-file-to-volume.ipynb
          # note the at the environment for notebook tasks is part of the notebook itself. 
          # environment_key: make_ames

        - task_key: refresh_pipeline
          depends_on:
            - task_key: copy_data_set
          pipeline_task:
            pipeline_id: ${resources.pipelines.ames_housing_pipeline.id}
            full_refresh: true


